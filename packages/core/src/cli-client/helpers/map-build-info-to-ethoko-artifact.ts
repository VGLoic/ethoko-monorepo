import { EthokoArtifact } from "@/utils/artifacts-schemas/ethoko-v0";
import fs from "fs/promises";
import { CliError } from "../error";
import { toAsyncResult, toResult } from "@/utils/result";
import { HardhatV2CompilerOutputSchema } from "@/utils/artifacts-schemas/hardhat-v2";
import {
  ForgeCompilerDefaultOutputSchema,
  ForgeCompilerOutputWithBuildInfoOptionSchema,
} from "@/utils/artifacts-schemas/forge-v1";
import { deriveEthokoArtifactId } from "@/utils/derive-ethoko-artifact-id";
import type { BuildInfoPath } from "./look-for-build-info-json-file";
import {
  HardhatV3CompilerInputPieceSchema,
  HardhatV3CompilerOutputPieceSchema,
} from "@/utils/artifacts-schemas/hardhat-v3";
import { forgeArtifactsToEthokoArtifact } from "./forge-artifacts-to-ethoko-artifact";

/**
 * Given a path to a candidate build info JSON file, try to output a EthokoArtifact.
 *
 * This function is meant to be used in other CLI client methods, since it throws a CliError, it can be used without any wrapping, i.e.
 * ```ts
 * const {artifact, originalContentPaths} = await mapBuildInfoToEthokoArtifact(buildInfoPath);
 * ```
 *
 * The format of the build info has already been detected previously by the caller.
 * According to the detected format, this function will fully satisfy the build info content, validate it and map it to the EthokoArtifact format.
 *
 * @param buildInfoPath The candidate build info path to parse and map to a EthokoArtifact, it contains both the format and the path to the build info JSON files
 * @param debug Whether to enable debug logging
 * @return The EthokoArtifact mapped from the build info JSON file and the paths to the original content files
 * @throws A CliError if the file cannot be parsed, if the build info is not valid or if the mapping fails
 */
export async function mapBuildInfoToEthokoArtifact(
  buildInfoPath: BuildInfoPath,
  debug: boolean,
): Promise<{ artifact: EthokoArtifact; originalContentPaths: string[] }> {
  if (buildInfoPath.format === "hardhat-v3") {
    // @dev readJsonFile throws a CliError so it is safe to use it directly without wrapping it in a try catch block
    const inputJsonContent = await readJsonFile(
      buildInfoPath.inputPath,
      "build info input",
      debug,
    );

    const inputParsingResult =
      HardhatV3CompilerInputPieceSchema.safeParse(inputJsonContent);
    if (!inputParsingResult.success) {
      if (debug) {
        console.error(
          `Failed to parse the build info input file "${buildInfoPath.inputPath}" as a Hardhat V3 compiler input piece. Error: ${inputParsingResult.error}`,
        );
      }
      throw new CliError(
        `The provided build info input file "${buildInfoPath.inputPath}" seems to be in the Hardhat V3 compiler input piece format but we failed to validate it. Please provide a valid Hardhat V3 compiler input piece JSON file. Run with debug mode for more info.`,
      );
    }

    // @dev readJsonFile throws a CliError so it is safe to use it directly without wrapping it in a try catch block
    const outputJsonContent = await readJsonFile(
      buildInfoPath.outputPath,
      "build info output",
      debug,
    );

    const outputParsingResult =
      HardhatV3CompilerOutputPieceSchema.safeParse(outputJsonContent);
    if (!outputParsingResult.success) {
      if (debug) {
        console.error(
          `Failed to parse the build info output file "${buildInfoPath.outputPath}" as a Hardhat V3 compiler output piece. Error: ${outputParsingResult.error}`,
        );
      }
      throw new CliError(
        `The provided build info output file "${buildInfoPath.outputPath}" seems to be in the Hardhat V3 compiler output piece format but we failed to validate it. Please provide a valid Hardhat V3 compiler output piece JSON file. Run with debug mode for more info.`,
      );
    }

    if (inputParsingResult.data.id !== outputParsingResult.data.id) {
      if (debug) {
        console.error(
          `The input and output files provided do not seem to belong together, their ids are different. Input id: "${inputParsingResult.data.id}", output id: "${outputParsingResult.data.id}". Please provide matching input and output files. Run with debug mode for more info.`,
        );
      }
      throw new CliError(
        `The input and output files provided do not seem to belong together, their ids are different. Please provide matching input and output files. Run with debug mode for more info.`,
      );
    }

    return {
      artifact: {
        id: deriveEthokoArtifactId(outputParsingResult.data.output),
        origin: {
          id: inputParsingResult.data.id,
          format: inputParsingResult.data._format,
          outputFormat: outputParsingResult.data._format,
        },
        input: inputParsingResult.data.input,
        output: outputParsingResult.data.output,
        solcLongVersion: inputParsingResult.data.solcLongVersion,
      },
      originalContentPaths: [buildInfoPath.inputPath, buildInfoPath.outputPath],
    };
  }

  // @dev readJsonFile throws a CliError so it is safe to use it directly without wrapping it in a try catch block
  const jsonContent = await readJsonFile(
    buildInfoPath.path,
    "build info",
    debug,
  );

  // We validate the content and map it to the EthokoArtifact format based on the previously detected format

  if (buildInfoPath.format === "hardhat-v2") {
    const parsingResult = HardhatV2CompilerOutputSchema.safeParse(jsonContent);
    if (!parsingResult.success) {
      if (debug) {
        console.error(
          `Failed to parse the build info file "${buildInfoPath.path}" as a Hardhat V2 build info format. Error: ${parsingResult.error}`,
        );
      }
      throw new CliError(
        `The provided build info file "${buildInfoPath.path}" seems to be in the Hardhat V2 format but we failed to validate it. Please provide a valid Hardhat V2 build info JSON file. Run with debug mode for more info.`,
      );
    }
    return {
      artifact: {
        id: deriveEthokoArtifactId(parsingResult.data.output),
        origin: {
          id: parsingResult.data.id,
          format: parsingResult.data._format,
        },
        solcLongVersion: parsingResult.data.solcLongVersion,
        input: parsingResult.data.input,
        output: parsingResult.data.output,
      },
      originalContentPaths: [buildInfoPath.path],
    };
  }

  if (buildInfoPath.format === "forge-with-build-info-option") {
    const parsingResult =
      ForgeCompilerOutputWithBuildInfoOptionSchema.safeParse(jsonContent);
    if (!parsingResult.success) {
      if (debug) {
        console.error(
          `Failed to parse the build info file "${buildInfoPath.path}" as a Forge build info format with the build info option. Error: ${parsingResult.error}`,
        );
      }
      throw new CliError(
        `The provided build info file "${buildInfoPath.path}" seems to be in the Forge format with the build info option but we failed to validate it. Please provide a valid Forge build info JSON file with the build info option. Run with debug mode for more info.`,
      );
    }
    return {
      artifact: {
        id: deriveEthokoArtifactId(parsingResult.data.output),
        origin: {
          id: parsingResult.data.id,
          format: parsingResult.data._format,
        },
        solcLongVersion: parsingResult.data.solcLongVersion,
        input: parsingResult.data.input,
        output: parsingResult.data.output,
      },
      originalContentPaths: [buildInfoPath.path],
    };
  }

  if (buildInfoPath.format === "forge-default") {
    const parsingResult =
      ForgeCompilerDefaultOutputSchema.safeParse(jsonContent);
    if (!parsingResult.success) {
      if (debug) {
        console.error(
          `Failed to parse the build info file "${buildInfoPath.path}" as a Forge build info format without the build info option. Error: ${parsingResult.error}`,
        );
      }
      throw new CliError(
        `The provided build info file "${buildInfoPath.path}" seems to be in the Forge format without the build info option but we failed to validate it. Please provide a valid Forge build info JSON file without the build info option. Run with debug mode for more info.`,
      );
    }
    // The mapping is not straightforward as we need to reconstruct the input and output from the scattered contract pieces
    const mappingResult = await toAsyncResult(
      forgeArtifactsToEthokoArtifact(
        buildInfoPath.path,
        parsingResult.data,
        debug,
      ),
      { debug },
    );
    if (!mappingResult.success) {
      throw new CliError(
        `The provided build info file "${buildInfoPath.path}" seems to be in the Foundry default format but we failed to validate it, please try to build with the "--build-info" option or file an issue with the error details.`,
      );
    }
    return {
      artifact: mappingResult.value.artifact,
      originalContentPaths: mappingResult.value.additionalArtifactsPaths.concat(
        buildInfoPath.path,
      ),
    };
  }

  buildInfoPath.format satisfies never; // to ensure we covered all the cases

  throw new CliError(
    `The provided build info file "${buildInfoPath.path}" does not match any of the supported formats. Please provide a valid build info JSON file. Run with debug mode for more info.`,
  );
}

async function readJsonFile(
  path: string,
  displayName: string,
  debug: boolean,
): Promise<unknown> {
  const contentResult = await toAsyncResult(fs.readFile(path, "utf-8"), {
    debug,
  });
  if (!contentResult.success) {
    throw new CliError(
      `The provided ${displayName} path "${path}" could not be read. Please check the permissions and try again. Run with debug mode for more info.`,
    );
  }
  const jsonContentResult = await toResult(
    () => JSON.parse(contentResult.value),
    { debug },
  );
  if (!jsonContentResult.success) {
    throw new CliError(
      `The provided ${displayName} file "${path}" could not be parsed as JSON. Please provide a valid JSON file. Run with debug mode for more info.`,
    );
  }
  return jsonContentResult.value;
}
